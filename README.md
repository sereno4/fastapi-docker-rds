## üéØ Para Recrutadores (Leia em 2 minutos)

## üí° O Problema que Resolvo

Empresas perdem oportunidades porque:
- Dados ficam presos em planilhas
- N√£o h√° visibilidade em tempo real
- Decis√µes s√£o baseadas em intui√ß√£o, n√£o em fatos

## ‚úÖ Minha Solu√ß√£o

Um **ecossistema unificado** que transforma opera√ß√µes di√°rias em intelig√™ncia acion√°vel:

1. **Coleta segura** ‚Üí API REST com autentica√ß√£o enterprise-grade (JWT + 2FA)
2. **Orquestra√ß√£o inteligente** ‚Üí Airflow executa ETLs e monitora sa√∫de do sistema
3. **Observabilidade total** ‚Üí M√©tricas de neg√≥cio no Grafana (vendas, usu√°rios, lat√™ncia)
4. **Previs√£o com ML** ‚Üí Modelo preditivo com contexto (feriados, final de semana)
5. **Automa√ß√£o serverless** ‚Üí Lambda gera gr√°ficos automaticamente a partir de Excel no S3
6. **Infraestrutura como C√≥digo** ‚Üí Terraform provisiona toda a stack na AWS com seguran√ßa

‚û°Ô∏è **Resultado**: decis√µes mais r√°pidas, estoque otimizado e redu√ß√£o de riscos operacionais.

**O que este projeto resolve:**
Sistema real de controle de estoque com processamento automatizado
de dados, usado por empresas que precisam monitorar invent√°rio 24/7.

**Tecnologias principais:**
FastAPI | Airflow | AWS | Docker | Terraform | Grafana | Lambda| S3 | Prometheus | IAM | Ecs | 
CloudWatch |  Neo4j

**Demonstra compet√™ncia em:**
- Arquitetura de sistemas escal√°veis
- Seguran√ßa (autentica√ß√£o enterprise-grade)
- DevOps e Cloud (AWS com IaC)
- Engenharia de dados (pipelines ETL)

**Tempo de setup:** 5 minutos com Docker Compose

üöÄ Portf√≥lio T√©cnico: Sistema Integrado de APIs, Orquestra√ß√£o de Dados e Observabilidade
Um ecossistema completo de microsservi√ßos em Python, Docker e AWS, unindo FastAPI (backend seguro com JWT + 2FA), Apache Airflow (pipelines ETL orquestrados), Prometheus/Grafana (monitoramento com m√©tricas de neg√≥cio) e serverless com AWS Lambda (processamento autom√°tico de arquivos).
Tudo provisionado com Infraestrutura como C√≥digo (Terraform), protegido por regras de seguran√ßa no banco de dados (triggers SQL), e preparado para produ√ß√£o com CI/CD, alertas inteligentes e arquitetura escal√°vel. ( Resumo)

üöÄ FastAPI + Airflow: Sistema Integrado de Monitoramento e Orquestra√ß√£o de Dados aws 

Um sistema completo de microservi√ßos para monitoramento, processamento de dados e orquestra√ß√£o com autentica√ß√£o avan√ßada, alertas em tempo real e escalabilidade nativa em containers.

üìã √çndice
Vis√£o Geral

Arquitetura do Sistema

Funcionalidades Principais

Tecnologias Utilizadas

üöÄ Como Executar o Projeto

üì° API FastAPI - Endpoints

‚öôÔ∏è Airflow - DAGs e Orquestra√ß√£o

üîê Sistema de Seguran√ßa

‚ö†Ô∏è Sistema de Alertas

üõ†Ô∏è Comandos √öteis

üìä Monitoramento e M√©tricas

üìà Pr√≥ximos Passos

üéØ Habilidades Demonstradas

üìÑ Licen√ßa

Vis√£o Geral
Este projeto implementa uma arquitetura moderna de microsservi√ßos integrando FastAPI para APIs RESTful e Apache Airflow para orquestra√ß√£o de pipelines de dados. O sistema inclui autentica√ß√£o JWT com 2FA, monitoramento autom√°tico, sistema de alertas em tempo real e processamento ETL escal√°vel, tudo containerizado com Docker e orquestrado via Docker Compose.

Objetivo Principal: Demonstrar habilidades completas em backend, engenharia de dados, DevOps e seguran√ßa, aplic√°veis a vagas de Engenheiro de Software, Engenheiro de Dados ou DevOps.

üèóÔ∏è Arquitetura do Sistema

https://imgur.com/a/Jp6YVlx

Fluxo de Dados:

API REST gerencia CRUD de embalagens com autentica√ß√£o robusta

Airflow monitora a API periodicamente e executa pipelines ETL

Sistema de Alertas detecta falhas e notifica em tempo real

Volume compartilhado permite integra√ß√£o entre servi√ßos

Dashboard consolida m√©tricas e relat√≥rios

‚ú® Funcionalidades Principais
üîê Autentica√ß√£o & Seguran√ßa
JWT com expira√ß√£o configur√°vel

Two-Factor Authentication (2FA) com QR Code

Hash de senhas com PBKDF2

Rate limiting em endpoints cr√≠ticos

CORS configurado

‚úÖ CI/CD com Terraform - Valida√ß√£o e Automa√ß√£o
Baseado na sua execu√ß√£o terraform validate, voc√™ implementou Infrastructure as Code (IaC) com boas pr√°ticas:
Fluxo CI/CD Implementado:
# 1. Valida√ß√£o da configura√ß√£o
terraform validate

# 2. Planejamento das mudan√ßas
terraform plan -out=tfplan

# 3. Aplica√ß√£o da infraestrutura
terraform apply tfplan

# 4. Configura√ß√£o do estado remoto no S3
terraform {
  backend "s3" {
    bucket = "seu-bucket-tfstate"
    key    = "projeto-airflow/terraform.tfstate"
    region = "us-east-1"
  }
}

Arquitetura AWS Provisionada (Terraform):
# Estrutura provisionada:
# ‚úÖ Amazon ECS + Fargate (Airflow + API)
# ‚úÖ Amazon RDS (PostgreSQL para Airflow)
# ‚úÖ Amazon ElastiCache (Redis para cache)
# ‚úÖ Amazon S3 (Buckets para dados/static files)
# ‚úÖ AWS Lambda (Processamento serverless)
# ‚úÖ CloudWatch (Logs e m√©tricas)
# ‚úÖ IAM Roles (Princ√≠pio do menor privil√©gio)
# ‚úÖ Security Groups (Firewall configurado)

Pipeline CI/CD Completo

.github/workflows/terraform.yml

name: 'Terraform CI/CD'

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v3
      
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0
        
    - name: Terraform Init
      run: terraform init
      
    - name: Terraform Validate
      run: terraform validate
      
    - name: Terraform Plan
      run: terraform plan -out=tfplan
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        
    - name: Terraform Apply
      if: github.ref == 'refs/heads/main'
      run: terraform apply -auto-approve tfplan

      

üìä Processamento de Dados
Pipeline ETL completo com Pandas

Agrega√ß√µes e transforma√ß√µes em tempo real

Gera√ß√£o autom√°tica de relat√≥rios

Armazenamento em formatos estruturados (JSON, CSV)

‚ö° Monitoramento & Alertas
Health checks autom√°ticos a cada 30 minutos

Monitoramento de API, banco e cache

Sistema de alertas com m√∫ltiplos n√≠veis de severidade

Logs estruturados e centralizados

üîÑ Orquestra√ß√£o
DAGs configur√°veis no Airflow
meu-projeto-airflow/
‚îú‚îÄ‚îÄ terraform/                # Infraestrutura como c√≥digo
‚îÇ   ‚îú‚îÄ‚îÄ terraform.tf          # Arquivo principal (provider, ECS, S3, SG, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf          # Vari√°veis (regi√£o, nomes, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf            # Outputs (ex.: IP p√∫blico da task ECS)
‚îÇ   ‚îî‚îÄ‚îÄ README.md             # Documenta√ß√£o r√°pida de como aplicar
‚îÇ
‚îú‚îÄ‚îÄ airflow/                  # Configura√ß√£o do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ dags/                 # Suas DAGs personalizadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exemplo_dag.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outra_dag.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt      # Depend√™ncias extras do Airflow
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile            # Se quiser customizar a imagem do Airflow
‚îÇ
‚îú‚îÄ‚îÄ lambda/                   # Fun√ß√µes Lambda para automa√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ resize_images.py      # Exemplo: redimensionar imagens do S3
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt      # Depend√™ncias da fun√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ s3/                       # Conte√∫do p√∫blico do portf√≥lio
‚îÇ   ‚îú‚îÄ‚îÄ prints/               # Prints do Airflow e da infra
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airflow-dag.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ecs-task.png
‚îÇ   ‚îî‚îÄ‚îÄ index.html            # P√°gina simples do portf√≥lio (se usar static hosting)
‚îÇ
‚îî‚îÄ‚îÄ docs/                     # Documenta√ß√£o e diagramas
    ‚îú‚îÄ‚îÄ arquitetura.png       # Diagrama da arquitetura AWS
    ‚îî‚îÄ‚îÄ guia.md               # Explica√ß√£o passo a passo

usando terraform pra estruturar as permissoes , executar a estrutura do projeto
terraform init, terraform plan, terraform apply
https://terraformexecucao.s3.us-east-1.amazonaws.com/terraform.png

Agendamento flex√≠vel (cron expressions)

sistema rodando em docker e ambiente aws
https://arquivosprojeto.s3.us-east-1.amazonaws.com/dags+projeto.png


Execu√ß√£o distribu√≠da com Celery

Retry autom√°tico em falhas

üõ†Ô∏è Tecnologias Utilizadas
Categoria	Tecnologia	Vers√£o	Finalidade
Backend	FastAPI	0.104.1	Framework API REST ass√≠ncrono
ORM	SQLAlchemy	2.0.23	Mapeamento objeto-relacional
Banco de Dados	PostgreSQL	13	Banco relacional principal
Cache	Redis	7	Sess√µes e cache de dados
Autentica√ß√£o	PyOTP, python-jose	2.8.0	2FA e tokens JWT
Orquestra√ß√£o	Apache Airflow	2.7.3	Pipeline e agendamento
Processamento	Pandas	2.1.4	Transforma√ß√£o de dados
Container	Docker	3.8	Containeriza√ß√£o
Orquestra√ß√£o	Docker Compose	3.8	Multi-container management
Cloud	AWS RDS	-	Banco de dados gerenciado
üöÄ Como Executar o Projeto
Pr√©-requisitos
Docker e Docker Compose instalados

4GB RAM dispon√≠vel

Python 3.9+ (para desenvolvimento local)

Passo a Passo
Clone o reposit√≥rio

bash
git clone https://github.com/seu-usuario/fastapi-airflow-system.git
cd fastapi-airflow-system
Configure as vari√°veis de ambiente

bash
cp .env.example .env
# Edite o .env com suas configura√ß√µes
Inicialize os servi√ßos

bash
# 1. Suba os servi√ßos base
docker-compose up -d redis airflow-postgres

# 2. Aguarde a inicializa√ß√£o
sleep 15

# 3. Inicialize o Airflow
docker-compose up -d airflow-init

# 4. Suba os servi√ßos principais
docker-compose up -d airflow-webserver airflow-scheduler airflow-worker api

# 5. Verifique o status
docker-compose ps
Acesse as interfaces
sistema de api com sistema financeiro da empresa
http://localhost:8001/docs
http://localhost:8002/docs
http://localhost:8003/docs
FastAPI API: http://localhost:8004/docs
Airflow UI: http://localhost:8080 (usu√°rio: , senha: )
API Docs (Swagger): http://localhost:8004/docs

üì¶ Projeto: Automa√ß√£o de Gera√ß√£o de Gr√°ficos a partir de Planilhas Excel no S3
üéØ Objetivo
Automatizar o processamento de planilhas Excel enviadas para um bucket S3, gerando gr√°ficos visuais com base nos dados e armazenando as imagens resultantes no pr√≥prio S3 ‚Äî tudo de forma serverless, escal√°vel e sem necessidade de servidores ou balanceadores de carga.

| Componente          | Fun√ß√£o                                                                 |
|---------------------|------------------------------------------------------------------------|
| **Amazon S3**       | Armazena arquivos Excel enviados (`uploads/`) e gr√°ficos gerados (`graficos/`) |
| **AWS Lambda**      | Fun√ß√£o Python que processa o Excel, gera o gr√°fico com `matplotlib` e salva como `.png` |
| **Lambda Layer**    | Cont√©m bibliotecas `pandas` e `matplotlib` para leitura e visualiza√ß√£o de dados |
| **CloudWatch Logs** | Registra logs de execu√ß√£o e erros para observabilidade e auditoria |
| **IAM Role**        | Permiss√µes para leitura/escrita no S3 e envio de logs ao CloudWatch |
| **S3 Event Trigger**| Dispara a fun√ß√£o Lambda automaticamente ao detectar novos arquivos `.xlsx` em `uploads/` |

üìä Vis√£o geral do fluxo
- Voc√™ envia um arquivo .xlsx para s3://arquivosprojeto/uploads/
- Uma fun√ß√£o Lambda √© acionada automaticamente
- Ela l√™ os dados com pandas, gera um gr√°fico com matplotlib
- Salva a imagem .png em s3://arquivosprojeto/graficos/

-  Funcionamento
- O usu√°rio envia uma planilha Excel para s3://arquivosprojeto/uploads/
- O S3 dispara automaticamente a fun√ß√£o Lambda
- A Lambda:
- L√™ o arquivo com pandas
- Gera um gr√°fico de barras com matplotlib
- Salva a imagem como .png em s3://arquivosprojeto/graficos/
- Logs s√£o registrados no CloudWatch para auditoria e depura√ß√£o


-  Seguran√ßa e boas pr√°ticas
- IAM com princ√≠pio do menor privil√©gio
- Filtros de prefixo/sufixo no trigger S3 para evitar execu√ß√µes indevidas
- Logs estruturados no CloudWatch
- Uso de /tmp para manipula√ß√£o segura de arquivos na Lambda

- print das primeiras configura√ß√µes com gatilhos em arquivo prefixo upload e sufixos formato excel
- codigo python pra Lambda:
- https://graficoexcel.s3.us-east-1.amazonaws.com/graficos3.png
- L√™ o arquivo com pandas
- Gera um gr√°fico de barras com matplotlib
- Salva a imagem como .png em s3://arquivosprojeto/graficos/
- Logs s√£o registrados no CloudWatch para auditoria e depura√ß√£o

implementei regras de negocios e seguran√ßa no banco de dados com gatilhos 

# Triggers do Banco de Dados "lab"

## Vis√£o Geral
Total de 10 triggers implementados para garantir:
- Integridade de dados
- Auditoria e logging
- Regras de neg√≥cio autom√°ticas
- Consist√™ncia entre tabelas relacionadas

## Categorias

### 1. Triggers de Auditoria/Logging (4)
- `trg_auditar_lab` (tabela `lab`)
- `trg_lab_log` (tabela `lab`)
- `trg_auditar_lab1` (tabela `lab1`)
- `trg_log_pedidos` (tabela `pedidos`)

### 2. Triggers de Regras de Neg√≥cio (3)
- `trg_atualizar_estoque` (tabela `pedido_itens`)
- `trg_validar_limite_credito` (tabela `pedidos`)
- `trg_atualizar_pagamento` (tabela `pedidos`)

### 3. Triggers de Manuten√ß√£o de Dados (3)
- `trg_lab_stats` (tabela `lab`)
- `trg_atualizar_valor_pedido` (tabela `pedido_itens`)
- `trg_atualizar_ultima_compra` (tabela `pedidos`)

- segue um print pra validar o processo

- https://triggersql.s3.us-east-1.amazonaws.com/triggers+banco+de+dados.png

Execute as DAGs iniciais


# üìä Intelig√™ncia de Dados: An√°lise Preditiva de Vendas

Sistema automatizado que transforma dados brutos de vendas em **insights acion√°veis**, **dashboards visuais** e **previs√µes de receita** usando Python, AWS S3 e Machine Learning.  
Ideal para PMEs que desejam tomar decis√µes baseadas em dados reais.

segue o grafico https://arquivosprojeto.s3.us-east-1.amazonaws.com/ML+preditiva+de+vendas+e+estoque.png

3. Arquitetura do Sistema em mermaid

https://arquivosprojeto.s3.us-east-1.amazonaws.com/diagrama.png

4. Resultados com Prints (Se√ß√£o Mais Importante!)
üìà 1. Total de Vendas Anual
"Vis√£o macro do desempenho financeiro"
https://arquivosprojeto.s3.us-east-1.amazonaws.com/grafico+vendas+anual.png

üèÜ 2. Top Produtos por Receita
"Identifica√ß√£o de herois de vendas e oportunidades de cross-sell"
https://arquivosprojeto.s3.us-east-1.amazonaws.com/grafico+vendas+produto+anual.png

3. Participa√ß√£o no Faturamento (Donut)
"Entendimento da depend√™ncia por categoria"

 üìä 4. KPIs Estrat√©gicos
"M√©tricas que guiam decis√µes: ticket m√©dio, sazonalidade, etc."
https://arquivosprojeto.s3.us-east-1.amazonaws.com/kpi1.png

parte 2 https://arquivosprojeto.s3.us-east-1.amazonaws.com/kpi2.png

ü§ñ 5. Previs√£o de Vendas com ML
"Planejamento de estoque e or√ßamento baseado em dados"

https://arquivosprojeto.s3.us-east-1.amazonaws.com/ML+preditiva+de+vendas+e+estoque.png

## üí° O Desafio
Empresas perdem oportunidades por:
- Dados de vendas isolados em planilhas
- Falta de visibilidade em tempo real
- Decis√µes baseadas em intui√ß√£o, n√£o em dados

## ‚úÖ Minha Solu√ß√£o
Um pipeline **end-to-end** que:
1. **Armazena** dados no AWS S3 (escal√°vel e seguro)
2. **Processa** com Python/Pandas (limpeza e agrega√ß√£o)
3. **Visualiza** KPIs cr√≠ticos em gr√°ficos intuitivos
4. **Prev√™** vendas futuras com Machine Learning

- **Armazenamento**: AWS S3
- **Processamento**: Python, Pandas, Scikit-learn
- **Visualiza√ß√£o**: Matplotlib, Seaborn
- **Machine Learning**: Random Forest Regressor
- **Automa√ß√£o**: Google Colab (agendamento via GitHub Actions

# üöÄ API Monitorada com Flask, Prometheus e Grafana

Este projeto demonstra uma API REST simples em **Python/Flask** com **monitoramento integrado** usando **Prometheus** (coleta de m√©tricas) e **Grafana** (visualiza√ß√£o). Ideal para aprender observabilidade, m√©tricas de neg√≥cio e SRE em aplica√ß√µes web.


## üì¶ Funcionalidades

- ‚úÖ Endpoints REST simulando opera√ß√µes de neg√≥cio (vendas, usu√°rios, erros)
- ‚úÖ M√©tricas autom√°ticas de HTTP (lat√™ncia, status, contagem)
- ‚úÖ M√©tricas personalizadas:
  - `active_users`: n√∫mero de usu√°rios ativos
  - `sales_total`: valor total de vendas em R$
- ‚úÖ Integra√ß√£o nativa com **Prometheus**
- ‚úÖ Dashboard pronto para **Grafana**
- ‚úÖ Simula√ß√£o de comportamentos reais: endpoints lentos, erros aleat√≥rios, tr√°fego em background

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Backend**: Python 3.9 + Flask
- **Monitoramento**: Prometheus + Grafana
- **Orquestra√ß√£o**: Docker + Docker Compose
- **M√©tricas**: `prometheus_client` (Python)

---

## üö¶ Como Executar

### Pr√©-requisitos
- [Docker](https://www.docker.com/)
- [Docker Compose](https://docs.docker.com/compose/)

- .
‚îú‚îÄ‚îÄ app.py                 # Aplica√ß√£o Flask principal
‚îú‚îÄ‚îÄ Dockerfile             # Imagem do container da API
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îú‚îÄ‚îÄ docker-compose.yml     # Orquestra√ß√£o (API, Prometheus, Grafana)
‚îú‚îÄ‚îÄ prometheus.yml         # Configura√ß√£o do Prometheus
‚îî‚îÄ‚îÄ grafana/               # (opcional) Provisionamento de dashboards

Acesse os endpoints:
API: http://localhost:5000
M√©tricas: http://localhost:5000/metrics
Prometheus: http://localhost:9090
Grafana: http://localhost:3000

imagens dos graficos
https://arquivosprojeto.s3.us-east-1.amazonaws.com/prometheus.png
https://arquivosprojeto.s3.us-east-1.amazonaws.com/promethieus+1.png

Grafico em grafana monitoramento de vendas em tempo real 
https://arquivosprojeto.s3.us-east-1.amazonaws.com/grafana+vendas.png


bash
# Listar DAGs dispon√≠veis
docker-compose exec airflow-webserver airflow dags list

# Executar DAG de monitoramento
docker-compose exec airflow-webserver airflow dags trigger monitor_api
üì° API FastAPI - Endpoints Principais
üîê Autentica√ß√£o
M√©todo	Endpoint	Descri√ß√£o
POST	/login	Autentica√ß√£o com JWT
POST	/2fa/enable	Ativa 2FA (retorna QR Code)
POST	/2fa/verify	Verifica c√≥digo 2FA
üì¶ CRUD Embalagens
M√©todo	Endpoint	Descri√ß√£o
GET	/embalagens	Lista todas embalagens
GET	/embalagens/{id}	Busca embalagem espec√≠fica
POST	/embalagens	Cria nova embalagem
PUT	/embalagens/{id}	Atualiza embalagem
DELETE	/embalagens/{id}	Remove embalagem
ü©∫ Sa√∫de do Sistema
M√©todo	Endpoint	Descri√ß√£o
GET	/health	Status da API, DB e Redis
GET	/metrics	M√©tricas de performance
GET	/api/relatorios	Lista relat√≥rios dispon√≠veis
üîî Webhooks
M√©todo	Endpoint	Descri√ß√£o
POST	/webhook/airflow	Aciona DAGs baseado em eventos
‚öôÔ∏è Airflow - DAGs e Orquestra√ß√£o
DAGs Implementadas
monitor_api - A cada 30 minutos

Verifica sa√∫de da API

Coleta m√©tricas de performance

Registra em arquivo JSON para an√°lise

process_data - Diariamente √†s 2h

Pipeline ETL completo

Extrai dados da API

Transforma com Pandas

Gera relat√≥rios agregados

hello_airflow - DAG de exemplo

Demonstra√ß√£o de tarefas simples

Template para novas DAGs

Agendamento
python
# Exemplos de schedule_interval
'@daily'           # Diariamente √† meia-noite
'@hourly'          # A cada hora
'*/30 * * * *'     # A cada 30 minutos
'0 2 * * *'        # Diariamente √†s 2h
'0 9-17 * * 1-5'   # Hora em hora, dias √∫teis
üîê Sistema de Seguran√ßa
Camadas de Prote√ß√£o
Autentica√ß√£o: JWT + 2FA para admin

Autoriza√ß√£o: RBAC baseado em roles

Valida√ß√£o: Pydantic para todos os inputs

Rate Limiting: Limite de requisi√ß√µes por usu√°rio

CORS: Origens configur√°veis

HTTPS Ready: Pronto para SSL/TLS

Implementa√ß√£o 2FA
python
# Gera√ß√£o de QR Code para app autenticador
@app.post("/2fa/enable")
def enable_2fa():
    secret = pyotp.random_base32()
    totp_url = pyotp.totp.TOTP(secret).provisioning_uri(
        name=user.username,
        issuer_name="API Embalagens"
    )
    # Retorna QR Code em base64
‚ö†Ô∏è Sistema de Alertas
N√≠veis de Severidade
python
SEVERITY_LEVELS = {
    'INFO': 'üü¢',      # Informa√ß√£o
    'WARNING': 'üü°',   # Aten√ß√£o necess√°ria
    'ERROR': 'üî¥',     # Falha recuper√°vel
    'CRITICAL': '‚ö´'   # Falha cr√≠tica
}
Alertas Configurados
DB_CONNECTION_LOST: Banco indispon√≠vel

API_HIGH_LATENCY: Lat√™ncia > 5 segundos

AIRFLOW_DAG_FAILED: Falha em execu√ß√£o de DAG

LOW_DISK_SPACE: Espa√ßo em disco < 10%

Canais de Notifica√ß√£o
Arquivo de log (alerts.log)

Email (SMTP configur√°vel)

Slack Webhook (pronto para implementa√ß√£o)

Dashboard em tempo real

üõ†Ô∏è Comandos √öteis
Docker & Airflow
bash
# Status dos containers
docker-compose ps

# Logs em tempo real
docker-compose logs -f api
docker-compose logs -f airflow-scheduler

# Acessar containers
docker-compose exec api bash
docker-compose exec airflow-webserver bash

# Gerenciar DAGs
docker-compose exec airflow-webserver airflow dags list
docker-compose exec airflow-webserver airflow dags pause monitor_api
docker-compose exec airflow-webserver airflow dags trigger process_data

# Backup do banco
docker-compose exec airflow-postgres pg_dump -U airflow airflow > backup.sql
Testes da API
bash
# Health check
curl http://localhost:8004/health

# Autentica√ß√£o
curl -X POST http://localhost:8004/login \
  -H "Content-Type: application/json" \
  -d '{"username":"admin","password":"admin"}'

# Listar embalagens (com token)
curl http://localhost:8004/embalagens \
  -H "Authorization: Bearer SEU_TOKEN_JWT"
Monitoramento Avan√ßado
bash
# Uso de recursos
docker stats

# Inspecionar rede
docker network inspect projeto_default

# Logs com filtro
docker-compose logs api | grep -i error
docker-compose logs --tail=100 --follow airflow-webserver
üìä Monitoramento e M√©tricas
M√©tricas Coletadas
json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "api_status": "ok",
  "database_status": "connected",
  "cache_status": "connected",
  "response_time": 0.145,
  "active_users": 42,
  "embalagens_count": 1250
}
KPIs do Sistema
M√©trica	Alvo	Monitoramento
Uptime API	> 99.9%	Health checks
Lat√™ncia	< 200ms	M√©tricas cont√≠nuas
Taxa de erro	< 0.1%	Logs agregados
Sucesso DAGs	> 95%	Airflow metrics
Tempo resposta alertas	< 5min	Sistema de alertas
Freshness dos dados	< 15min	Timestamps

üìà Pr√≥ximos Passos
üéØ Curto Prazo (1-2 semanas)
Implementar testes automatizados com Pytest

Adicionar documenta√ß√£o Swagger completa

Configurar CI/CD com GitHub Actions

Dashboard Grafana para m√©tricas

üöÄ M√©dio Prazo (1 m√™s)
Mais DAGs de processamento complexo

Cache Redis avan√ßado com invalidation

Autentica√ß√£o OAuth2 com providers externos

Ambientes staging/production separados

üåü Longo Prazo (3+ meses)
Migra√ß√£o para Kubernetes

Streaming com Apache Kafka

Pipelines de machine learning

Arquitetura multi-tenancy

üéØ Habilidades Demonstradas
üèóÔ∏è Engenharia de Software
Arquitetura de microsservi√ßos

Design de APIs RESTful com FastAPI

Padr√µes de projeto e clean code

Versionamento com Git

üóÑÔ∏è Engenharia de Dados
Pipeline ETL com Airflow e Pandas

Processamento e agrega√ß√£o de dados

Quality assurance de dados

Orquestra√ß√£o complexa de workflows

‚òÅÔ∏è DevOps & SRE
Containeriza√ß√£o com Docker

Orquestra√ß√£o com Docker Compose

Monitoramento proativo e alertas

Infraestrutura como c√≥digo

üîí Seguran√ßa
Autentica√ß√£o JWT e 2FA

Autoriza√ß√£o baseada em roles

Rate limiting e CORS

Prote√ß√£o de dados sens√≠veis

üìä Monitoramento & Observabilidade
Health checks automatizados

M√©tricas e logging estruturado

Sistema de alertas escal√°vel

Dashboard de performance

üîÑ Integra√ß√£o & APIs
Comunica√ß√£o entre servi√ßos

Webhooks e eventos

Volume compartilhado entre containers

API documentation autom√°tica

üìÑ Licen√ßa
Este projeto est√° licenciado sob a MIT License - veja o arquivo LICENSE para detalhes.

ü§ù Contribui√ß√£o
Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues e pull requests.

Fork o projeto

Crie sua feature branch (git checkout -b feature/AmazingFeature)

Commit suas mudan√ßas (git commit -m 'Add some AmazingFeature')

Push para a branch (git push origin feature/AmazingFeature)

Abra um Pull Request

üìû Contato 24981042582
Se voc√™ est√° interessado em uma demonstra√ß√£o ou tem oportunidades profissionais:
LinkedIn: Daniel Fonseca https://www.linkedin.com/in/daniel-fonseca-a56159128/

GitHub: @seu-usuario

Portf√≥lio: seu-portfolio.com

https://imgur.com/a/Jp6YVlx fotos sistema em produ√ß√£o

Nota: Este projeto est√° pronto para produ√ß√£o e demonstra compet√™ncia t√©cnica em m√∫ltiplas √°reas relevantes para vagas de engenharia de software, dados e DevOps.
